{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e029fcc4-dd53-485f-bf99-1f5718905e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import json\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import string\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36d0a3ac-9ffe-492c-8579-cf693e6f2725",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_file(file_path):\n",
    "    if file_path.endswith('.jl'):\n",
    "        return pd.read_json(file_path, lines=True)\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)\n",
    "\n",
    "train_path = \"poquad-train.json\"\n",
    "val_path = \"poquad-dev.json\"\n",
    "train_data = load_json_file(train_path)['data']\n",
    "val_data = load_json_file(val_path)['data']\n",
    "\n",
    "questions_path = \"lab9_data/questions.jl\"\n",
    "answers_path = \"lab9_data/answers.jl\"\n",
    "passages_path = \"lab9_data/passages.jl\"\n",
    "relevant_path = \"lab9_data/relevant.jl\"\n",
    "questions = load_json_file(questions_path)\n",
    "answers = load_json_file(answers_path)\n",
    "passages = load_json_file(passages_path)\n",
    "relevant = load_json_file(relevant_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56c83d08-fcba-4cf4-b5b0-3b27be8b1243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46187\n",
      "5764\n"
     ]
    }
   ],
   "source": [
    "def preprocess_data(data):\n",
    "    examples = []\n",
    "    for article in data:\n",
    "        for paragraph in article['paragraphs']:\n",
    "            context = paragraph['context']\n",
    "            for qa in paragraph['qas']:\n",
    "                question = qa['question']\n",
    "                if 'answers' in qa and qa['answers']:\n",
    "                    for answer in qa['answers']:\n",
    "                        output_text = answer['text']\n",
    "                        input_text = f\"Pytanie: {question}; kontekst: {context}\"\n",
    "                        examples.append((input_text, output_text))\n",
    "    return examples\n",
    "\n",
    "qa_train = preprocess_data(train_data)\n",
    "qa_val = preprocess_data(val_data)\n",
    "print(len(qa_train))\n",
    "print(len(qa_val))\n",
    "\n",
    "qa_val_df = pd.DataFrame(qa_val, columns=['question','answer'])\n",
    "qa_train_df = pd.DataFrame(qa_train, columns=['question','answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5807ff-e5ce-4d76-a1d7-275e87932f07",
   "metadata": {},
   "source": [
    "I am using the trained model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b194660-46c2-4c31-8dba-60fc3875751f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"apohllo/plt5-base-poquad\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"apohllo/plt5-base-poquad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7a776ca7-8549-4895-9b5f-72266ab8f088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pytanie: Czy żołnierz, który dopuszcza się czy...</td>\n",
       "      <td>Tak, podlega karze aresztu wojskowego albo poz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pytanie: Z ilu osób składa się komisja przetar...</td>\n",
       "      <td>Komisja przetargowa składa się z co najmniej t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pytanie: Do jakiej wysokości za zobowiązania s...</td>\n",
       "      <td>Komandytariusz odpowiada za zobowiązania spółk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pytanie: Kiedy ustala się wartość majątku obro...</td>\n",
       "      <td>Wartość rzeczowych składników majątku obrotowe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pytanie: Jakiej karze podlega armator, który w...</td>\n",
       "      <td>Podlega karze pieniężnej do wysokości 1 000 00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>pytanie: Jakim przepisom podlegają przychody k...</td>\n",
       "      <td>ogólnym przepisom podatkowym, z wyjątkami okre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677</th>\n",
       "      <td>pytanie: Jakim przepisom podlegają przychody k...</td>\n",
       "      <td>ogólnym przepisom podatkowym, z wyjątkami okre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>pytanie: Jakim przepisom podlegają przychody k...</td>\n",
       "      <td>ogólnym przepisom podatkowym, a w szczególnośc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>679</th>\n",
       "      <td>pytanie: Jakim przepisom podlegają przychody k...</td>\n",
       "      <td>ogólnym przepisom podatkowym, z wyjątkami okre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>680</th>\n",
       "      <td>pytanie: Według jakiego prawa wyraz \"kosmetyki...</td>\n",
       "      <td>ustawa z dnia 4 października 2018 r. o produkt...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>681 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "0    pytanie: Czy żołnierz, który dopuszcza się czy...   \n",
       "1    pytanie: Z ilu osób składa się komisja przetar...   \n",
       "2    pytanie: Do jakiej wysokości za zobowiązania s...   \n",
       "3    pytanie: Kiedy ustala się wartość majątku obro...   \n",
       "4    pytanie: Jakiej karze podlega armator, który w...   \n",
       "..                                                 ...   \n",
       "676  pytanie: Jakim przepisom podlegają przychody k...   \n",
       "677  pytanie: Jakim przepisom podlegają przychody k...   \n",
       "678  pytanie: Jakim przepisom podlegają przychody k...   \n",
       "679  pytanie: Jakim przepisom podlegają przychody k...   \n",
       "680  pytanie: Według jakiego prawa wyraz \"kosmetyki...   \n",
       "\n",
       "                                                answer  \n",
       "0    Tak, podlega karze aresztu wojskowego albo poz...  \n",
       "1    Komisja przetargowa składa się z co najmniej t...  \n",
       "2    Komandytariusz odpowiada za zobowiązania spółk...  \n",
       "3    Wartość rzeczowych składników majątku obrotowe...  \n",
       "4    Podlega karze pieniężnej do wysokości 1 000 00...  \n",
       "..                                                 ...  \n",
       "676  ogólnym przepisom podatkowym, z wyjątkami okre...  \n",
       "677  ogólnym przepisom podatkowym, z wyjątkami okre...  \n",
       "678  ogólnym przepisom podatkowym, a w szczególnośc...  \n",
       "679  ogólnym przepisom podatkowym, z wyjątkami okre...  \n",
       "680  ustawa z dnia 4 października 2018 r. o produkt...  \n",
       "\n",
       "[681 rows x 2 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa = pd.merge(questions, answers, left_on=\"_id\", right_on=\"question-id\")\n",
    "qa = pd.merge(qa, relevant, on=\"question-id\")\n",
    "qa = pd.merge(qa, passages, left_on=\"passage-id\", right_on=\"_id\")\n",
    "qa = qa[['text_x', 'answer', 'text_y']]\n",
    "qa.columns=['question', 'answer', 'context']\n",
    "qa[\"question\"] = qa.apply(lambda row: f\"pytanie: {row['question']}; kontekst: {row['context']}\", axis=1)\n",
    "qa.drop(columns='context')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6c63f97e-3219-4b93-9691-8179a38bcd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(f\"[{string.punctuation}]\", \"\", text)\n",
    "    return text\n",
    "\n",
    "def compute_metrics(reference_answers, predicted_answers):\n",
    "    exact_matches = 0\n",
    "    total = len(reference_answers)\n",
    "    f1_scores = []\n",
    "    \n",
    "    for ref, pred in zip(reference_answers, predicted_answers):\n",
    "\n",
    "        # Preprocessing to skip punctuation marks and converting to lower\n",
    "        ref = preprocess(ref)\n",
    "        pred = preprocess(pred)\n",
    "        \n",
    "        ref_tokens = ref.split()\n",
    "        pred_tokens = pred.split()\n",
    "\n",
    "        if ref == pred:\n",
    "            exact_matches += 1\n",
    "        \n",
    "        # F1 score\n",
    "        common = set(ref_tokens) & set(pred_tokens)\n",
    "        precision = len(common) / len(pred_tokens) if pred_tokens else 0\n",
    "        recall = len(common) / len(ref_tokens) if ref_tokens else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "        f1_scores.append(f1)\n",
    "    \n",
    "    # metrics computing\n",
    "    exact_match = (exact_matches / total) * 100\n",
    "    avg_f1 = (sum(f1_scores) / total) * 100\n",
    "    \n",
    "    return {\"EM\": round(exact_match,4), \"F1\": round(avg_f1,4)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0b3d4c92-35f3-4007-b0f0-8950b476a605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answers(questions):\n",
    "    generated_answers = []\n",
    "\n",
    "    for i, question in enumerate(questions):\n",
    "        inputs = tokenizer(question, return_tensors=\"pt\")\n",
    "        outputs = model.generate(**inputs, max_length=50)\n",
    "        answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        generated_answers.append(answer)\n",
    "    \n",
    "        # Printing progress\n",
    "        if i % 100 == 0 and i > 0:\n",
    "            print(f\"Processed {round(i/len(questions)*100,2)}% questions so far\")\n",
    "\n",
    "\n",
    "    return generated_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "bca96541-f03a-47b7-acad-9c71cd0a0090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 14.68% questions so far\n",
      "Processed 29.37% questions so far\n",
      "Processed 44.05% questions so far\n",
      "Processed 58.74% questions so far\n",
      "Processed 73.42% questions so far\n",
      "Processed 88.11% questions so far\n"
     ]
    }
   ],
   "source": [
    "qa_questions = list(qa['question'])\n",
    "qa_correct_answers = list(qa['answer'])\n",
    "qa_generated_answers = generate_answers(qa_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bda5e0c9-619e-4680-9fb8-42e5974b2c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EM': 24.6696, 'F1': 43.8787}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(qa_generated_answers, qa_correct_answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb09bd3-440e-42e3-b4de-882a04de8f88",
   "metadata": {},
   "source": [
    "| **Metric** | **Score (%)** |\n",
    "|------------|---------------|\n",
    "| Exact Match (EM) | 24.6696          |\n",
    "| F1 Score        | 43.8787          |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "97cbf6b4-49e1-4461-9ecc-e4c10d09487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa['generated_answer'] = qa_generated_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2ec65a39-c447-4eda-be53-31c7564a0565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 1.73% questions so far\n",
      "Processed 3.47% questions so far\n",
      "Processed 5.2% questions so far\n",
      "Processed 6.94% questions so far\n",
      "Processed 8.67% questions so far\n",
      "Processed 10.41% questions so far\n",
      "Processed 12.14% questions so far\n",
      "Processed 13.88% questions so far\n",
      "Processed 15.61% questions so far\n",
      "Processed 17.35% questions so far\n",
      "Processed 19.08% questions so far\n",
      "Processed 20.82% questions so far\n",
      "Processed 22.55% questions so far\n",
      "Processed 24.29% questions so far\n",
      "Processed 26.02% questions so far\n",
      "Processed 27.76% questions so far\n",
      "Processed 29.49% questions so far\n",
      "Processed 31.23% questions so far\n",
      "Processed 32.96% questions so far\n",
      "Processed 34.7% questions so far\n",
      "Processed 36.43% questions so far\n",
      "Processed 38.17% questions so far\n",
      "Processed 39.9% questions so far\n",
      "Processed 41.64% questions so far\n",
      "Processed 43.37% questions so far\n",
      "Processed 45.11% questions so far\n",
      "Processed 46.84% questions so far\n",
      "Processed 48.58% questions so far\n",
      "Processed 50.31% questions so far\n",
      "Processed 52.05% questions so far\n",
      "Processed 53.78% questions so far\n",
      "Processed 55.52% questions so far\n",
      "Processed 57.25% questions so far\n",
      "Processed 58.99% questions so far\n",
      "Processed 60.72% questions so far\n",
      "Processed 62.46% questions so far\n",
      "Processed 64.19% questions so far\n",
      "Processed 65.93% questions so far\n",
      "Processed 67.66% questions so far\n",
      "Processed 69.4% questions so far\n",
      "Processed 71.13% questions so far\n",
      "Processed 72.87% questions so far\n",
      "Processed 74.6% questions so far\n",
      "Processed 76.34% questions so far\n",
      "Processed 78.07% questions so far\n",
      "Processed 79.81% questions so far\n",
      "Processed 81.54% questions so far\n",
      "Processed 83.28% questions so far\n",
      "Processed 85.01% questions so far\n",
      "Processed 86.75% questions so far\n",
      "Processed 88.48% questions so far\n",
      "Processed 90.22% questions so far\n",
      "Processed 91.95% questions so far\n",
      "Processed 93.68% questions so far\n",
      "Processed 95.42% questions so far\n",
      "Processed 97.15% questions so far\n",
      "Processed 98.89% questions so far\n"
     ]
    }
   ],
   "source": [
    "qa_val_questions = list(qa_val_df['question'])\n",
    "qa_val_correct_answers = list(qa_val_df['answer'])\n",
    "qa_val_generated_answers = generate_answers(qa_val_questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "86e16c31-5ec5-437b-8475-c28e21c5d6e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EM': 42.3144, 'F1': 59.7899}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(qa_val_correct_answers, qa_val_generated_answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c90993b-e2fe-4bc6-9b0b-5c71716d0662",
   "metadata": {},
   "source": [
    "| **Metric** | **Score (%)** |\n",
    "|------------|---------------|\n",
    "| Exact Match (EM) | 42.3144         |\n",
    "| F1 Score        | 59.7899          |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "a6ba9bd1-327e-4655-b436-6d46f29b11d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_val_df['generated answer'] = qa_val_generated_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "e028abb0-2b35-4530-ba0d-46f450911b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1_scores(reference_answers, predicted_answers):\n",
    "    total = len(reference_answers)\n",
    "    f1_scores = []\n",
    "    \n",
    "    for ref, pred in zip(reference_answers, predicted_answers):\n",
    "\n",
    "        # Preprocessing to skip punctuation marks and converting to lower\n",
    "        ref = preprocess(ref)\n",
    "        pred = preprocess(pred)\n",
    "        \n",
    "        ref_tokens = ref.split()\n",
    "        pred_tokens = pred.split()\n",
    "        \n",
    "        # F1 score\n",
    "        common = set(ref_tokens) & set(pred_tokens)\n",
    "        precision = len(common) / len(pred_tokens) if pred_tokens else 0\n",
    "        recall = len(common) / len(ref_tokens) if ref_tokens else 0\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if precision + recall > 0 else 0\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    return f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "0153d9ae-a4a9-4156-9ec6-6fa8103d9860",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = get_f1_scores(qa_val_generated_answers, qa_val_correct_answers) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "51ac0916-3edd-44b8-8ecc-91e6a72a40cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_val_df['f1-score'] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "f7016365-5c15-4e0b-8cb3-6d0c6d90bff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>generated answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pytanie: Z ilu komponentów składała się Tora p...</td>\n",
       "      <td>dwóch</td>\n",
       "      <td>1.0</td>\n",
       "      <td>dwóch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pytanie: Kto początkowo należał do oddziału st...</td>\n",
       "      <td>280 strzelców, kilkuset chłopów kosynierów i 6...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>280 strzelców, kilkuset chłopów kosynierów i 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pytanie: Kiedy Plater wraz z oddziałem dotarła...</td>\n",
       "      <td>29 marca 1831</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29 marca 1831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Pytanie: Wynagrodzenie w jakiej wysokości otrz...</td>\n",
       "      <td>pięćset tysięcy funtów</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pięćset tysięcy funtów</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Pytanie: Co oprócz placków ziemniaczanych smaż...</td>\n",
       "      <td>pączki, faworki i bliny</td>\n",
       "      <td>1.0</td>\n",
       "      <td>pączki, faworki i bliny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5732</th>\n",
       "      <td>Pytanie: Jak wyglądała próba zmierzenia się te...</td>\n",
       "      <td>nagrywając koncert na orkiestrę i grupę rockową</td>\n",
       "      <td>1.0</td>\n",
       "      <td>nagrywając koncert na orkiestrę i grupę rockową</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5739</th>\n",
       "      <td>Pytanie: W jakim języku pisał Agatiasz?; konte...</td>\n",
       "      <td>attyckim</td>\n",
       "      <td>1.0</td>\n",
       "      <td>attyckim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5748</th>\n",
       "      <td>Pytanie: Na jakim stanowisku pracował w klinic...</td>\n",
       "      <td>młodszego rezydenta</td>\n",
       "      <td>1.0</td>\n",
       "      <td>młodszego rezydenta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5755</th>\n",
       "      <td>Pytanie: Kto stanął na czele nowo powstałej ra...</td>\n",
       "      <td>Walancina Żukouska</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Walancina Żukouska</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5758</th>\n",
       "      <td>Pytanie: Co sprawia, że na wyspie Uznam występ...</td>\n",
       "      <td>ukształtowanie terenu</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ukształtowanie terenu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2336 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question  \\\n",
       "1     Pytanie: Z ilu komponentów składała się Tora p...   \n",
       "4     Pytanie: Kto początkowo należał do oddziału st...   \n",
       "5     Pytanie: Kiedy Plater wraz z oddziałem dotarła...   \n",
       "10    Pytanie: Wynagrodzenie w jakiej wysokości otrz...   \n",
       "14    Pytanie: Co oprócz placków ziemniaczanych smaż...   \n",
       "...                                                 ...   \n",
       "5732  Pytanie: Jak wyglądała próba zmierzenia się te...   \n",
       "5739  Pytanie: W jakim języku pisał Agatiasz?; konte...   \n",
       "5748  Pytanie: Na jakim stanowisku pracował w klinic...   \n",
       "5755  Pytanie: Kto stanął na czele nowo powstałej ra...   \n",
       "5758  Pytanie: Co sprawia, że na wyspie Uznam występ...   \n",
       "\n",
       "                                                 answer  f1-score  \\\n",
       "1                                                 dwóch       1.0   \n",
       "4     280 strzelców, kilkuset chłopów kosynierów i 6...       1.0   \n",
       "5                                         29 marca 1831       1.0   \n",
       "10                               pięćset tysięcy funtów       1.0   \n",
       "14                              pączki, faworki i bliny       1.0   \n",
       "...                                                 ...       ...   \n",
       "5732    nagrywając koncert na orkiestrę i grupę rockową       1.0   \n",
       "5739                                           attyckim       1.0   \n",
       "5748                                młodszego rezydenta       1.0   \n",
       "5755                                 Walancina Żukouska       1.0   \n",
       "5758                              ukształtowanie terenu       1.0   \n",
       "\n",
       "                                       generated answer  \n",
       "1                                                 dwóch  \n",
       "4     280 strzelców, kilkuset chłopów kosynierów i 6...  \n",
       "5                                         29 marca 1831  \n",
       "10                               pięćset tysięcy funtów  \n",
       "14                              pączki, faworki i bliny  \n",
       "...                                                 ...  \n",
       "5732    nagrywając koncert na orkiestrę i grupę rockową  \n",
       "5739                                           attyckim  \n",
       "5748                                młodszego rezydenta  \n",
       "5755                                 Walancina Żukouska  \n",
       "5758                              ukształtowanie terenu  \n",
       "\n",
       "[2336 rows x 4 columns]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_val_df[qa_val_df['f1-score'] == 1.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "18441c52-cd90-45e8-8813-91a705ebbec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_ids = []\n",
    "for i in range(10):\n",
    "    random_id = random.randint(0, len(qa)-1)\n",
    "    random_ids.append(random_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "0a62c130-8885-4c39-9f44-24e0ff678b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 pytanie: Jakim warunkom powinny odpowiadać przekazywane gminie urządzenia wodociągowe? \n",
      "\n",
      "GENERATED ANSWER:  technicznym określonym w odrębnych przepisach\n",
      "CORRECT ANSWER:  Przekazywane urządzenia powinny odpowiadać warunkom technicznym określonym w odrębnych przepisach. \n",
      "\n",
      "2 pytanie: Czy za użytkowanie wieczyste gruntów przez zakłady charytatywno-opiekuńcze pobiera się opłaty? \n",
      "\n",
      "GENERATED ANSWER:  nie\n",
      "CORRECT ANSWER:  Nie. \n",
      "\n",
      "3 pytanie: Co robi się z każdorazowym wypadkiem zastosowania tymczasowego aresztowania wobec obywatela państwa obcego? \n",
      "\n",
      "GENERATED ANSWER:  zawiadamia się niezwłocznie właściwy miejscowo urząd konsularny tego państwa - lub w braku takiego urzędu - przedstawicielstwo dyplomatyczne tego państwa\n",
      "CORRECT ANSWER:  W przypadku każdorazowego wypadku zastosowania tymczasowego aresztowania wobec obywatela państwa obcego, należy zawiadomić konsula tego państwa o fakcie zastosowania aresztowania (zgodnie z ustawą o postępowaniu wobec cudzoziemców). \n",
      "\n",
      "4 pytanie: Na jakie cele może wydawać środki komitet wyborczy? \n",
      "\n",
      "GENERATED ANSWER:  związane z wyborami\n",
      "CORRECT ANSWER:  jedynie na cele związane z wyborami \n",
      "\n",
      "5 pytanie: Na co przeznacza się Środki Funduszu Rozwoju? \n",
      "\n",
      "GENERATED ANSWER:  finansowanie działań w zakresie resocjalizacji osób pozbawionych wolności\n",
      "CORRECT ANSWER:  Środki Funduszu Rozwoju są przeznaczane na finansowanie projektów w zakresie rozwoju gospodarczego, w tym przedsiębiorczości, innowacji, modernizacji i internacjonalizacji oraz na podejmowanie innych działań związanych z rozwojem gospodarczym (zgodnie z ustawą o Funduszu Rozwoju Przedsiębiorczości). \n",
      "\n",
      "6 pytanie: Czy osoba udzielająca pierwszej pomocy może poświęcić mienie drugiej osoby w stopniu niezbędnym do ratowania życia? \n",
      "\n",
      "GENERATED ANSWER:  nie\n",
      "CORRECT ANSWER:  Tak \n",
      "\n",
      "7 pytanie: Czy marszałek województwa jest uprawniony do skracania okresów polowań na terenie województwa? \n",
      "\n",
      "GENERATED ANSWER:  tak\n",
      "CORRECT ANSWER:  Nie \n",
      "\n",
      "8 pytanie: Co zawiera rejestr grup? \n",
      "\n",
      "GENERATED ANSWER:  nazwę i adres grupy, 2) datę i numer wydania decyzji o wpisie grupy do rejestru, 3) grupę produktów objętych decyzją, 4) informacje o osobach upoważnionych do reprezentowania grupy\n",
      "CORRECT ANSWER:  Rejestr grup uznanych zawiera nazwę i adres grupy, datę i numer wydania decyzji o wpisie grupy do rejestru, grupę produktów objętych decyzją i informacje o osobach upoważnionych do reprezentowania grupy. \n",
      "\n",
      "9 pytanie: Jak wysoka jest kara dla uchylającego się od służby funkcjonariusza BOR? \n",
      "\n",
      "GENERATED ANSWER:  od 3 miesięcy do lat 5\n",
      "CORRECT ANSWER:  od 3 miesięcy do lat 5 \n",
      "\n",
      "10 pytanie: Jaki akt wygasa wraz z dniem powołania Prezesa UDT? \n",
      "\n",
      "GENERATED ANSWER:  powołanie Prezesa Urzędu Dozoru Technicznego\n",
      "CORRECT ANSWER:  wygasa akt powołania Prezesa Urzędu Dozoru Technicznego \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, id in enumerate(random_ids):\n",
    "    item = qa.iloc[id]  # Zakładam, że `qa` to DataFrame pandas\n",
    "    question = item['question'].split(\";\")[0]  # Bierzemy tylko część przed średnikiem\n",
    "    print(i+1, question.strip(), \"\\n\")  # Usuń zbędne spacje, jeśli są\n",
    "    print(\"GENERATED ANSWER: \", item['generated_answer'])\n",
    "    print(\"CORRECT ANSWER: \", item['answer'], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd48bdf-8309-478f-9799-5e6eea4b7a39",
   "metadata": {},
   "source": [
    "We can see that the model is capable of answering questions, but it does so in a minimalist and straightforward manner. It operates like an Extractive QA system because it doesn’t provide full-sentence answers; instead, it returns only the most relevant fragments from the context provided for the question. Generally, it answers correctly, although it does make mistakes (for example, it gave incorrect answers to questions 6 and 7, even though the answer is a single word)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03e0c72-e610-4a8f-915b-f4ca99e0c034",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c952c8eb-87af-4084-9f7d-58756f2d1b45",
   "metadata": {},
   "source": [
    "### 1. Does the performance on the validation dataset reflects the performance on your test set?\n",
    "\n",
    "The performance on the test and validation datasets present as follows:\n",
    "\n",
    "| **Dataset** | **Metric** | **Score (%)** |\n",
    "|------------|------------|---------------|\n",
    "| Test | Exact Match (EM) | 24.6696          |\n",
    "| Test | F1 Score        | 43.8787          |\n",
    "| Validation | Exact Match (EM) | 42.3144         |\n",
    "| Validation | F1 Score        | 59.7899         |\n",
    "\n",
    "In my opiniom the differences are significant enough that it is not possible to definitively state that the validation set adequately reflects the model's later performance. \n",
    "\n",
    "### 2. What are the outcomes of the model on your test questions? Are they satisfying? If not, what might be the reason for that?\n",
    "\n",
    "The model performs quite well. Although the metric values are not very high, we must remember that this is not a typical classification task, and the way the metrics are calculated heavily depends on the specific answer someone considers correct. In fact, we could equally well phrase a correct answer in a slightly different way, and it would not necessarily have an F1-score of 100%. The model doesn't generate full-sentence answers but instead extracts key fragments from the context. It occasionally makes mistakes, but in my opinion, this model is already on the edge of being usable for cases where we don't need to be absolutely certain about the information we obtain. The observed differences between datasets may result from different grammatical structures in the questions, or from more diverse questions in the test dataset, even though they concern the same topic.\n",
    "\n",
    "### 3. Why extractive question answering is not well suited for inflectional languages?\n",
    "\n",
    "In inflectional languages, the issue lies in the quality control of answers. When comparing individual tokens, we may fail to match the same word in a different form, which means we won't consider it correct. Additionally, in such languages, changes in grammatical forms can significantly impact meaning, making it more difficult to correctly match answers in extractive QA tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa93404-a017-449d-b429-eaa334741464",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
