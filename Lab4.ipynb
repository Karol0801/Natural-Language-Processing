{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef3463b3-e227-4874-9362-e1fc6a3cdae3",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM, AutoModelForCausalLM\n",
    "import torch\n",
    "import logging\n",
    "logging.getLogger(\"transformers\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94e3ac8b-8345-4140-885b-780c34315501",
   "metadata": {},
   "outputs": [],
   "source": [
    "herbert_model = AutoModelForMaskedLM.from_pretrained(\"allegro/herbert-large-cased\")\n",
    "herbert_tokenizer = AutoTokenizer.from_pretrained(\"allegro/herbert-large-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b42bb08-b8fa-486a-98b4-13d0a84354d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlm_model = AutoModelForMaskedLM.from_pretrained(\"xlm-roberta-base\")\n",
    "xlm_tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04d2536e-1495-4b45-b07d-edb78fc69792",
   "metadata": {},
   "outputs": [],
   "source": [
    "mbert_model = AutoModelForMaskedLM.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "mbert_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22f80f6f-7755-49e2-a5a9-9ba351e66d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_case(model, tokenizer, sentence, k):\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "    mask_token_index = torch.where(inputs[\"input_ids\"] == tokenizer.mask_token_id)[1]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    logits = outputs.logits\n",
    "    mask_token_logits = logits[0, mask_token_index, :]\n",
    "\n",
    "    top_tokens = torch.topk(mask_token_logits, k, dim=1).indices[0].tolist()\n",
    "    predictions = [tokenizer.decode([token]).strip() for token in top_tokens]\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bff2b4e-bacf-4c08-b69d-e728a47ed3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_sentence(sentence, model_name):\n",
    "    if model_name in ['herbert', 'xlm']:\n",
    "        return sentence.replace(\"{mask}\", \"<mask>\")\n",
    "    else:\n",
    "        return sentence.replace(\"{mask}\", \"[MASK]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0a51d02-5f28-47b5-bcd9-b01a19c9ab07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_predictions(base_sentences, num_predictions):\n",
    "    for sentence in base_sentences:\n",
    "        # Przygotowanie zdań dla każdego modelu\n",
    "        sentences_herbert = prepare_sentence(sentence, 'herbert')\n",
    "        sentences_xlm = prepare_sentence(sentence, 'xlm')\n",
    "        sentences_mbert = prepare_sentence(sentence, 'mbert')\n",
    "        \n",
    "        print(f\"\\nSentence: {sentence}\")\n",
    "        print(\"\\nHerBERT: \", predict_case(herbert_model, herbert_tokenizer, sentences_herbert, num_predictions))\n",
    "        print(\"XLM: \", predict_case(xlm_model, xlm_tokenizer, sentences_xlm, num_predictions))\n",
    "        print(\"Multilingual BERT: \", predict_case(mbert_model, mbert_tokenizer, sentences_mbert, num_predictions))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9d735d-ed70-4eed-a6aa-b25c21f7e1ad",
   "metadata": {},
   "source": [
    "### Testing polish cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "42c3d591-e8e0-4a2f-a071-c4e8558b86cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"Warszawa to największe {mask}.\", # mianownik\n",
    "    \"Musiałem oddać samochód do mechanika więc teraz funkcjonuję bez {mask}.\", # dopełniacz\n",
    "    \"Wczoraj w zoo przyglądałem się ogromnemu {mask}.\", # celownik\n",
    "    \"Wieczorem gdy robi się ciemno, zawsze do nauki zapalam {mask}.\", # biernik\n",
    "    \"Na zajęcia z przetwarzania języka naturalnego zawsze przychodzę z {mask}.\", #narzędnik\n",
    "    \"Polska posiada orła w swoim {mask}.\", # miejscownik\n",
    "    \"Zjadłeś całą kiełbasę! Ty denerwujący {mask}!\" # wołacz\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "650af39b-06c7-47f8-816c-5c5779b92e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence: Warszawa to największe {mask}.\n",
      "\n",
      "HerBERT:  ['miasto', 'miasta', '.', 'lotnisko', 'miast']\n",
      "XLM:  ['miasto', 'miasta', '', 'Miasto', 'city']\n",
      "Multilingual BERT:  ['miasto', 'miasta', 'woj', 'Warszawa', 'to']\n",
      "\n",
      "\n",
      "Sentence: Musiałem oddać samochód do mechanika więc teraz funkcjonuję bez {mask}.\n",
      "\n",
      "HerBERT:  ['problemu', 'samochodu', 'niego', 'auta', 'problemów']\n",
      "XLM:  ['problemu', 'problemów', 'zmian', 'niego', 'ruchu']\n",
      "Multilingual BERT:  ['tego', 'to', 'niego', 'tym', 'co']\n",
      "\n",
      "\n",
      "Sentence: Wczoraj w zoo przyglądałem się ogromnemu {mask}.\n",
      "\n",
      "HerBERT:  ['.', 'zamieszaniu', 'dziecku', 'stworzeniu', 'zoo']\n",
      "XLM:  ['zoo', 'parku', 'muzeum', 'polu', 'domu']\n",
      "Multilingual BERT:  ['stylu', 'życiu', 'zoo', 'sensu', 'św']\n",
      "\n",
      "\n",
      "Sentence: Wieczorem gdy robi się ciemno, zawsze do nauki zapalam {mask}.\n",
      "\n",
      "HerBERT:  ['światło', 'papierosa', 'świece', 'światła', 'ogień']\n",
      "XLM:  ['światło', 'telefon', 'komputer', 'alarm', 'akumulator']\n",
      "Multilingual BERT:  ['się', 'go', '!', 'słowa', 'siebie']\n",
      "\n",
      "\n",
      "Sentence: Na zajęcia z przetwarzania języka naturalnego zawsze przychodzę z {mask}.\n",
      "\n",
      "HerBERT:  ['dziećmi', 'psem', 'dzieckiem', 'rodzicami', 'grupą']\n",
      "XLM:  ['dziećmi', 'Warszawy', 'Polski', 'dzieckiem', 'domu']\n",
      "Multilingual BERT:  ['##d', 'pt', 'góry', '##w', 'łac']\n",
      "\n",
      "\n",
      "Sentence: Polska posiada orła w swoim {mask}.\n",
      "\n",
      "HerBERT:  ['logo', 'kraju', 'mundurze', 'symbolu', 'kolorze']\n",
      "XLM:  ['kraju', 'DNA', 'domu', 'rodzaju', 'parlamentu']\n",
      "Multilingual BERT:  ['herb', 'barwach', 'im', 'polu', 'kraju']\n",
      "\n",
      "\n",
      "Sentence: Zjadłeś całą kiełbasę! Ty denerwujący {mask}!\n",
      "\n",
      "HerBERT:  ['człowieku', 'mały', 'robocie', 'duchu', 'panie']\n",
      "XLM:  ['widok', 'człowiek', 'jesteś', 'obiad', 'chłopak']\n",
      "Multilingual BERT:  ['pan', 'język', 'stan', ',', 'się']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_predictions(sentences, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead62399-46d5-44fd-b110-ec4c3746a25c",
   "metadata": {},
   "source": [
    "### Testing long-range relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8629f00f-b90d-49af-b3dc-3f950f3597f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"Szarlotka mojej babci wyszła znakomicie, chociaż zbytnio mnie to nie dziwi, gdyż od zawsze {mask} wspaniałe ciasta.\",\n",
    "    \"Gdy uczestnik wszedł do pomieszczenia dla pracowników, ochroniarz momentalnie podbiegł do {mask}.\",\n",
    "    \"Skoro wygrała konkurs piękności, z pewnością musi być bardzo {mask}.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24b9c407-e5de-4b03-8e87-1c9404a625e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence: Szarlotka mojej babci wyszła znakomicie, chociaż zbytnio mnie to nie dziwi, gdyż od zawsze {mask} wspaniałe ciasta.\n",
      "\n",
      "HerBERT:  ['robiła', 'robi', 'lubiła', 'piekła', 'robię']\n",
      "XLM:  ['miałam', 'były', 'robi', 'lubię', 'miała']\n",
      "Multilingual BERT:  ['to', 'ma', 'jest', 'miała', '-']\n",
      "\n",
      "\n",
      "Sentence: Gdy uczestnik wszedł do pomieszczenia dla pracowników, ochroniarz momentalnie podbiegł do {mask}.\n",
      "\n",
      "HerBERT:  ['niego', 'drzwi', 'wejścia', 'okna', 'poszkodowanego']\n",
      "XLM:  ['niego', 'środka', 'drzwi', 'budynku', 'nich']\n",
      "Multilingual BERT:  ['tzw', 'niego', 'góry', 'budynku', 'samolotu']\n",
      "\n",
      "\n",
      "Sentence: Skoro wygrała konkurs piękności, z pewnością musi być bardzo {mask}.\n",
      "\n",
      "HerBERT:  ['szczęśliwa', 'zadowolona', 'popularna', 'atrakcyjna', 'piękna']\n",
      "XLM:  ['zadowolona', 'piękna', 'zadowolony', 'stara', 'ważna']\n",
      "Multilingual BERT:  ['dobrze', 'dużą', 'wiele', 'znana', 'średniej']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_predictions(sentences, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d501845a-ed45-43c2-917f-09bb9fcd74ac",
   "metadata": {},
   "source": [
    "### Testing real-world knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5ee856d0-87a7-40f8-af39-ffdd41ad2793",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"Ściana komórkowa zbudowana jest z mureiny, więc musi to być komórka {mask}.\",\n",
    "    \"Wybieram się do {mask}, najludniejszego państwa świata.\",\n",
    "    \"Ziemia jest {mask} w kolejności planetą od słońca.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f1a3c36-87f0-49ea-919c-aa77989fad41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence: Ściana komórkowa zbudowana jest z mureiny, więc musi to być komórka {mask}.\n",
      "\n",
      "HerBERT:  ['ludzka', 'DNA', 'żywa', 'czysta', 'właściwa']\n",
      "XLM:  ['.', 'ciepła', 'domu', ',', '...']\n",
      "Multilingual BERT:  ['tzw', 'ta', 'np', 'w', 'typu']\n",
      "\n",
      "\n",
      "Sentence: Wybieram się do {mask}, najludniejszego państwa świata.\n",
      "\n",
      "HerBERT:  ['Indii', 'Chin', 'Japonii', 'Australii', 'Meksyku']\n",
      "XLM:  ['Iraku', 'USA', 'Tokio', 'Peru', 'Zimbabwe']\n",
      "Multilingual BERT:  ['świata', 'tego', 'Europy', 'swojego', 'nowego']\n",
      "\n",
      "\n",
      "Sentence: Ziemia jest {mask} w kolejności planetą od słońca.\n",
      "\n",
      "HerBERT:  ['drugą', 'trzecią', 'czwartą', 'piątą', 'szóstą']\n",
      "XLM:  ['drugą', 'pierwszą', 'większą', 'druga', 'dalej']\n",
      "Multilingual BERT:  ['drugą', 'druga', 'pierwszą', 'się', 'drugim']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_predictions(sentences, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0deb8fa2-a4bf-47c9-ac0b-79cb1f09ba72",
   "metadata": {},
   "source": [
    "### Testing zero-shot learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67f87d1c-cfe9-41bb-a956-b44d70aba38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"'Wczoraj na urodzinach mojej babci bawiłem się jak nigdy dotąd! Bardzo szybko zleciał mi czas, zdecydowanie nie żałuję, że pojechałem' Wypowiedź ta jest zdecydowanie {mask}.\",\n",
    "    \"'To był najgorszy koncert, na którym byłem, muzycy spóźnili się, a dźwięk był fatalny, co całkowicie zepsuło atmosferę.' Wypowiedź ta jest zdecydowanie {mask}.\",\n",
    "    \"'Jedzenie w tej restauracji było pyszne! Każda potrawa była starannie przygotowana i podana z niezwykłą estetyką, co sprawiło, że chciałem wracać tam z przyjemnością.' Wypowiedź ta jest zdecydowanie {mask}.\",\n",
    "    \"'Nie polecam tej książki, straciłem czas, ponieważ fabuła była chaotyczna, a postacie płaskie i nieciekawe, przez co nie mogłem się skupić na czytaniu.' Wypowiedź ta jest zdecydowanie {mask}.\",\n",
    "    \"'Film był dość nudny, nie polecam, ponieważ tempo akcji było wolne, a dialogi mało interesujące, przez co odczuwałem znużenie.' Wypowiedź ta jest zdecydowanie {mask}.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "098cf6e8-34ef-4bc4-9ec1-478640f6a271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence: 'Wczoraj na urodzinach mojej babci bawiłem się jak nigdy dotąd! Bardzo szybko zleciał mi czas, zdecydowanie nie żałuję, że pojechałem' Wypowiedź ta jest zdecydowanie {mask}.\n",
      "\n",
      "HerBERT:  ['prawdziwa', 'pozytywna', 'oryginalna', 'najlepsza', 'wyjątkowa']\n",
      "XLM:  ['dobra', 'najlepsza', 'piękna', 'ważna', 'moja']\n",
      "Multilingual BERT:  ['słowa', 'znana', 'sama', 'folk', '##łowa']\n",
      "\n",
      "\n",
      "Sentence: 'To był najgorszy koncert, na którym byłem, muzycy spóźnili się, a dźwięk był fatalny, co całkowicie zepsuło atmosferę.' Wypowiedź ta jest zdecydowanie {mask}.\n",
      "\n",
      "HerBERT:  ['prawdziwa', 'pozytywna', 'najlepsza', 'oficjalna', 'oryginalna']\n",
      "XLM:  ['dobra', 'najlepsza', 'ważna', 'kontra', 'moja']\n",
      "Multilingual BERT:  ['słowa', 'znana', '##łowa', 'stała', 'ta']\n",
      "\n",
      "\n",
      "Sentence: 'Jedzenie w tej restauracji było pyszne! Każda potrawa była starannie przygotowana i podana z niezwykłą estetyką, co sprawiło, że chciałem wracać tam z przyjemnością.' Wypowiedź ta jest zdecydowanie {mask}.\n",
      "\n",
      "HerBERT:  ['prawdziwa', 'pozytywna', 'najlepsza', 'oryginalna', 'uzasadniona']\n",
      "XLM:  ['najlepsza', 'dobra', 'piękna', 'moja', 'ważna']\n",
      "Multilingual BERT:  ['słowa', 'ta', 'taka', 'znana', 'stała']\n",
      "\n",
      "\n",
      "Sentence: 'Nie polecam tej książki, straciłem czas, ponieważ fabuła była chaotyczna, a postacie płaskie i nieciekawe, przez co nie mogłem się skupić na czytaniu.' Wypowiedź ta jest zdecydowanie {mask}.\n",
      "\n",
      "HerBERT:  ['prawdziwa', 'pozytywna', 'najlepsza', 'oryginalna', 'uzasadniona']\n",
      "XLM:  ['dobra', 'najlepsza', 'kontra', 'ważna', 'taka']\n",
      "Multilingual BERT:  ['słowa', 'sama', 'znana', 'autora', 'ta']\n",
      "\n",
      "\n",
      "Sentence: 'Film był dość nudny, nie polecam, ponieważ tempo akcji było wolne, a dialogi mało interesujące, przez co odczuwałem znużenie.' Wypowiedź ta jest zdecydowanie {mask}.\n",
      "\n",
      "HerBERT:  ['prawdziwa', 'pozytywna', 'najlepsza', 'słuszna', 'oryginalna']\n",
      "XLM:  ['dobra', 'najlepsza', 'moja', 'ok', 'taka']\n",
      "Multilingual BERT:  ['słowa', 'znana', 'stała', 'dobrze', 'ta']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_predictions(sentences, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e08341e-a325-4381-9fe6-18f43f19a669",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2eae10-579a-41f1-aff2-3a09d35a1b2a",
   "metadata": {},
   "source": [
    "### 1) Which of the models produced the best results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9df3200-26f4-4b7a-a34f-542c6c816f9f",
   "metadata": {},
   "source": [
    "Among the tested models, herBERT performed the best. This was an expected outcome, as herBERT was trained exclusively on Polish data, which allows it to better understand the specific characteristics of the Polish language."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1890163d-eaef-46d1-a32a-baeb41fd5bca",
   "metadata": {},
   "source": [
    "### 2) Was any of the models able to capture Polish grammar? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc340f4e-b5e1-495e-905e-08eb0597d9e6",
   "metadata": {},
   "source": [
    "The herBERT model can accurately match words in all Polish cases. The XLM-RoBERTa-based model also achieved good results, though it was not as consistent in every case as herBERT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650b4a80-be8c-40b3-9809-10e06a38a19d",
   "metadata": {},
   "source": [
    "### 3) Was any of the models able to capture long-distant relationships between the words?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ce833e-e20a-4b47-99e9-f96a5d9c606d",
   "metadata": {},
   "source": [
    "Both herBERT and XLM-Roberta performed strongly in this task, demonstrating high accuracy in correct matching. Despite the relatively short sentence lengths, multilingual BERT struggled to respond appropriately."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6efc283-dff9-407e-aa76-288112f9d678",
   "metadata": {},
   "source": [
    "### 4) Was any of the models able to capture world knowledge?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ee134a-073b-460a-91ba-d9f1be6a9d70",
   "metadata": {},
   "source": [
    "The models' knowledge of the world is strongly limited, but they are sometimes able to make accurate matches. For example, herBERT correctly identified India as the most populous country in the world, with China in second place. This is interesting, as China population was recently exceeded by India – this could indicate that the model was trained on relatively recent data, although it could also be a coincidence.\n",
    "It is also worth noting that all models gave the same incorrect answer to a question about the order of planets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2868ee7-ad20-4063-92f6-e83d8bd91b22",
   "metadata": {},
   "source": [
    "### 5) Was any of the models good at doing zero-shot classification?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86efffc9-4509-441a-bcbf-fb08fd336817",
   "metadata": {},
   "source": [
    "In this task, the models struggled to accurately evaluate the emotional tone of statements. They often asserted that a given opinion was \"prawdziwa\" or \"słuszna\", even when it was clearly negatively charged, indicating their limited ability to recognize emotional undertones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429211c4-cc8b-4519-9341-19ce163a3322",
   "metadata": {},
   "source": [
    "### 6) What are the most striking errors made by the models?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3116ae6-0f2d-48f0-b0a0-e3e8eba1b834",
   "metadata": {},
   "source": [
    "Although sentences often ended in the pattern “... {mask}.” (with a period after the mask), models frequently predicted this period within the text as well. Multilingual BERT had particular difficulty with context, likely due to its training across many languages – it is unable to retain grammatical structures for each one, so its predictions often seem random.\n",
    "The models frequently generated grammatically correct, but contextually incorrect, words. For example, in the sentence “Wczoraj w zoo przyglądałem się ogromnemu {mask}.” one would expect some animal rather than \"zamieszaniu\" or \"zoo.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a6418c-0777-41bd-98ba-9c18d67a5cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
