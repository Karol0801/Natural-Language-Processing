{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac9098fc-45e3-4677-bce0-92833d9a5e0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karol\\anaconda3\\envs\\NLP_spacy2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from collections import defaultdict, OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f788c429-13de-4cc8-a79e-c46e7c56590c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "\n",
    "# Wyłączenie ostrzeżeń\n",
    "warnings.simplefilter('ignore', InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "899ac366-82bd-4d56-bb0b-7b2405305d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Elasticsearch(\n",
    "    \"http://localhost:9200\",\n",
    "    basic_auth=(\"elastic\", \"<hidden>\"),\n",
    "    verify_certs=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e55c47a-6156-4694-9641-5973e1a813d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_definition = {\n",
    "    \"settings\": {\n",
    "        \"analysis\": {\n",
    "            \"filter\": {\n",
    "                \"synonym_filter\": {\n",
    "                    \"type\": \"synonym\",\n",
    "                    \"synonyms\": [\n",
    "                        \"styczeń, sty, I\",\n",
    "                        \"luty, lut, II\",\n",
    "                        \"marzec, mar, III\",\n",
    "                        \"kwiecień, kwi, IV\",\n",
    "                        \"maj, maj, V\",\n",
    "                        \"czerwiec, czer, VI\",\n",
    "                        \"lipiec, lip, VII\",\n",
    "                        \"sierpień, sie, VIII\",\n",
    "                        \"wrzesień, wrz, IX\",\n",
    "                        \"październik, paź, X\",\n",
    "                        \"listopad, lis, XI\",\n",
    "                        \"grudzień, gru, XII\"\n",
    "                    ]\n",
    "                }\n",
    "            },\n",
    "            \"analyzer\": {\n",
    "                \"analyzer_with_synonyms_with_lemmatizer\": {\n",
    "                    \"type\": \"custom\",\n",
    "                    \"tokenizer\": \"standard\",\n",
    "                    \"filter\": [\n",
    "                        \"lowercase\",\n",
    "                        \"synonym_filter\",\n",
    "                        \"morfologik_stem\",\n",
    "                        \"lowercase\"\n",
    "                    ]\n",
    "                },\n",
    "                \"analyzer_without_synonyms_with_lemmatizer\": {\n",
    "                    \"type\": \"custom\",\n",
    "                    \"tokenizer\": \"standard\",\n",
    "                    \"filter\": [\n",
    "                        \"lowercase\",\n",
    "                        \"morfologik_stem\",\n",
    "                        \"lowercase\"\n",
    "                    ]\n",
    "                },\n",
    "                \"analyzer_without_synonyms_without_lemmatizer\": {\n",
    "                    \"type\": \"custom\",\n",
    "                    \"tokenizer\": \"standard\",\n",
    "                    \"filter\": [\n",
    "                        \"lowercase\"\n",
    "                    ]\n",
    "                },\n",
    "                \"analyzer_with_synonyms_without_lemmatizer\": {\n",
    "                    \"type\": \"custom\",\n",
    "                    \"tokenizer\": \"standard\",\n",
    "                    \"filter\": [\n",
    "                        \"lowercase\",\n",
    "                        \"synonym_filter\"\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"with_synonyms_with_lemmatizer\": {\n",
    "                \"type\": \"text\",\n",
    "                \"analyzer\": \"analyzer_with_synonyms_with_lemmatizer\"\n",
    "            },\n",
    "            \"without_synonyms_with_lemmatizer\": {\n",
    "                \"type\": \"text\",\n",
    "                \"analyzer\": \"analyzer_without_synonyms_with_lemmatizer\"\n",
    "            },\n",
    "            \"with_synonyms_without_lemmatizer\": {\n",
    "                \"type\": \"text\",\n",
    "                \"analyzer\": \"analyzer_with_synonyms_without_lemmatizer\"\n",
    "            },\n",
    "            \"without_synonyms_without_lemmatizer\": {\n",
    "                \"type\": \"text\",\n",
    "                \"analyzer\": \"analyzer_without_synonyms_without_lemmatizer\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# client.indices.create(index='fiqa_pl_index_v3', body=index_definition)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27b6303-fbb2-422f-8eb6-a5dabd8f07bf",
   "metadata": {},
   "source": [
    "Ładowanie danych do indeksu - zakomentowane bo już są załadowane"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a559518d-bd17-41ec-8b98-b7648c6b4965",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"clarin-knext/fiqa-pl\", \"corpus\")\n",
    "\n",
    "# for item in ds['corpus']:\n",
    "#     document = {\n",
    "#         \"with_synonyms_with_lemmatizer\": item['text'],\n",
    "#         \"without_synonyms_with_lemmatizer\": item['text'],\n",
    "#         \"with_synonyms_without_lemmatizer\": item['text'],\n",
    "#         \"without_synonyms_without_lemmatizer\": item['text']\n",
    "#     }\n",
    "\n",
    "#     client.index(index=\"fiqa_pl_index_v3\", id=item['_id'], body=document)\n",
    "# WCZYTYWANIE V3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb2d2419-d7fd-47c7-a4ce-2697cdebe7c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokumenty zawierające 'kwiecień' (z synonimami): 306\n",
      "Dokumenty zawierające 'kwiecień' (bez synonimów): 257\n",
      "Liczba wszystkich dokumentów w indeksie: 57638\n"
     ]
    }
   ],
   "source": [
    "response_with_synonyms = client.search(\n",
    "    index=\"fiqa_pl_index_v3\",\n",
    "    body={\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                \"with_synonyms_with_lemmatizer\": \"kwiecień\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "response_without_synonyms = client.search(\n",
    "    index=\"fiqa_pl_index_v3\",\n",
    "    body={\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                \"without_synonyms_with_lemmatizer\": \"kwiecień\"\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "num_documents_with_synonyms = response_with_synonyms['hits']['total']['value']\n",
    "num_documents_without_synonyms = response_without_synonyms['hits']['total']['value']\n",
    "total_documents = client.count(index=\"fiqa_pl_index_v3\")['count']\n",
    "\n",
    "# Wyniki\n",
    "print(f\"Dokumenty zawierające 'kwiecień' (z synonimami): {num_documents_with_synonyms}\")\n",
    "print(f\"Dokumenty zawierające 'kwiecień' (bez synonimów): {num_documents_without_synonyms}\")\n",
    "print(f\"Liczba wszystkich dokumentów w indeksie: {total_documents}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7d8db2c-2b56-463b-b0c5-d3c1536f6dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_qa = load_dataset(\"clarin-knext/fiqa-pl-qrels\")['test'] # zbiór testowy pytań i odpowiedzi - dla niego mieliśmy policzyć NDCG\n",
    "ds_queries = load_dataset(\"clarin-knext/fiqa-pl\",\"queries\") # zapytania"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a7d34b-4297-49d5-8af6-a2b7e2100263",
   "metadata": {},
   "source": [
    "Tworzymy posortowanego orderedDicta tylko do zapytań, które znajdują się w zbiorze testowym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b575dabd-5730-4fd9-a062-e823daf300cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_query_ids = set(ds_qa['query-id'])\n",
    "filtered_queries = OrderedDict(sorted((int(row['_id']), row['text']) for row in ds_queries['queries'] if int(row['_id']) in test_query_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3eb82c6-8a2f-4d1f-aef5-9dc4fd67797d",
   "metadata": {},
   "source": [
    "Funkcja przeszukująca teksty dla podanego zestawu zapytań"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e5fec3a-aa11-444d-8b8e-971bca976a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_text(index_name: str, queries: dict, k: int):\n",
    "\n",
    "    model_results = [[] for _ in range(4)] \n",
    "    \n",
    "    for query_id, query_text in queries.items():\n",
    "        search_bodies = [\n",
    "            {\n",
    "                \"query\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query_text,\n",
    "                        \"fields\": [\"with_synonyms_with_lemmatizer\"]\n",
    "                    }\n",
    "                },\n",
    "                \"size\": k\n",
    "            },\n",
    "            {\n",
    "                \"query\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query_text,\n",
    "                        \"fields\": [\"without_synonyms_with_lemmatizer\"]\n",
    "                    }\n",
    "                },\n",
    "                \"size\": k\n",
    "            },\n",
    "            {\n",
    "                \"query\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query_text,\n",
    "                        \"fields\": [\"with_synonyms_without_lemmatizer\"]\n",
    "                    }\n",
    "                },\n",
    "                \"size\": k\n",
    "            },\n",
    "            {\n",
    "                \"query\": {\n",
    "                    \"multi_match\": {\n",
    "                        \"query\": query_text,\n",
    "                        \"fields\": [\"without_synonyms_without_lemmatizer\"]\n",
    "                    }\n",
    "                },\n",
    "                \"size\": k\n",
    "            }\n",
    "        ]\n",
    "    \n",
    "        # Wykonujemy zapytanie dla każdego analyzera i zapisujemy wyniki do odpowiedniej listy\n",
    "        for i, search_body in enumerate(search_bodies):\n",
    "            response = client.search(index=index_name, body=search_body)\n",
    "            \n",
    "            for hit in response['hits']['hits']:\n",
    "                model_results[i].append({\n",
    "                    'query-id': query_id,\n",
    "                    'corpus-id': int(hit['_id']),\n",
    "                    'analyzer': i\n",
    "                })\n",
    "\n",
    "    return model_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9982c373-b407-4097-bfb2-5caa68b3ed58",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = search_text(\"fiqa_pl_index_v3\", filtered_queries, 5) # NDCG 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ce8d1f5-3614-4a9e-98e0-a42c0dd591bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e38de2d-23bd-40b9-b737-f9d9d79d1dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_DCG(relevance_scores, k):\n",
    "    return sum(rel / np.log2(idx + 2) for idx, rel in enumerate(relevance_scores[:k]))\n",
    "\n",
    "def get_NDCG(model_results, relevant_documents, k):\n",
    "\n",
    "    relevance_scores = [1 if doc['corpus-id'] in relevant_documents else 0 for doc in model_results]\n",
    "    dcg_k = get_DCG(relevance_scores, k)\n",
    "\n",
    "    num_docs = len(relevant_documents)\n",
    "    ideal_relevance_scores = [1] * min(num_docs, k) + [0] * (k - min(num_docs, k))\n",
    "    idcg_k = get_DCG(ideal_relevance_scores, k)\n",
    "\n",
    "    ndcg_k = dcg_k / idcg_k if idcg_k > 0 else 0\n",
    "    return ndcg_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe4f8b8-96db-4e49-b10e-b6f0b13653de",
   "metadata": {},
   "source": [
    "Tworzymy listę prawidłowych dopasowań tekstów do zapytań"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afe623c4-e78f-4ba2-b631-a8b8aedd36c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_results = defaultdict(list)\n",
    "\n",
    "for entry in ds_qa:\n",
    "    query_id = entry['query-id']\n",
    "    corpus_id = entry['corpus-id']\n",
    "    correct_results[query_id].append(corpus_id)\n",
    "\n",
    "correct_list = [{'query-id': query_id, 'corpuses-id': corpuses} for query_id, corpuses in correct_results.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d47acaaa-80fd-4926-abaa-2be384cccb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndcgs = []\n",
    "k=5\n",
    "\n",
    "for j in range(len(search_results)):\n",
    "    results = []\n",
    "    for i in range(len(correct_list)):\n",
    "        ndcg = get_NDCG(search_results[j][i*k:(i+1)*k], correct_list[i]['corpuses-id'], k)\n",
    "        results.append((correct_list[i]['query-id'], float(ndcg)))\n",
    "\n",
    "    ndcgs.append(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5f1c53-2640-403f-ac16-ca6b4e27cfb5",
   "metadata": {},
   "source": [
    "0 - with synonyms with lemmatizer\n",
    "\n",
    "1 - without synonyms with lemmatizer\n",
    "\n",
    "2 - with synonyms without lemmatizer\n",
    "\n",
    "3 - without synonyms without lemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "806296d5-13e7-448e-94bc-a509be6ceb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 18.58 %\n",
      "1: 18.51 %\n",
      "2: 13.84 %\n",
      "3: 13.85 %\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(ndcgs)):\n",
    "    avg = sum(value for _, value in ndcgs[i]) / len(ndcgs[i])\n",
    "    print(f\"{i}: {round(avg*100,2)} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f981ea3-8108-4688-a246-825a7918b90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## KOD ZAKŁADA ZE WSZYSTKIE SCORY=1 <- mozna by zmienić"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec9dd02-57bb-499c-86f5-6eafa1178536",
   "metadata": {},
   "source": [
    "1. What are the strengths and weaknesses of regular expressions versus full text search regarding processing of text?\n",
    "   \n",
    "Regex must scan the entire document from start to finish with each search, making it effective for smaller datasets or specific text patterns. Regex provides greater control over the matching process, allowing for the detection of unusual or custom patterns. It works great in scenarios such as log file analysis, validating input data formats, or identifying highly specific text patterns like email addresses or dates.\n",
    "\n",
    "Full-text search however is better suited for handling large datasets. Although building the necessary indexes may take time, the subsequent search process is incredibly fast. FTS is also the ideal choice when the meaning and context of words are important, such as in searches where relevance, semantics, or synonyms matter. FTS is particularly effective for queries written in natural language (the way humans typically communicate), as it can account for the context, meaning, and variations of terms, such as synonyms, enhancing search accuracy and flexibility.\n",
    "\n",
    "2. Can an LLM be applied in the context of searching for documents? Justify your answer, excluding the obvious observation that an LLM can be used to formulate the answer.\n",
    "\n",
    "LLMs excel at grasping context, managing ambiguity, and continuously learning from data, leading to more accurate and relevant search results. This makes LLMs a powerful enhancement to document search, going beyond the capabilities of traditional FTS. By incorporating LLMs into a search system, the experience becomes more intelligent, allowing for intent-based analysis of user queries. As a result, the system can retrieve documents that don’t necessarily contain the exact keywords but are still highly relevant because they convey similar ideas or concepts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
