{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d475040e-4149-461f-b6d7-14da78a3e52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import json\n",
    "import ast\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3dbe6c67-5bb6-4424-8783-b260dc8a244a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"clarin-knext/fiqa-pl\", \"corpus\")\n",
    "df = pd.DataFrame(ds['corpus'])\n",
    "df = df.sample(n=10)\n",
    "text_list = [text for text in df['text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109a2438-41c6-4f88-bb85-0803cc87ab91",
   "metadata": {},
   "source": [
    "NER from lab 6 (baseline):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "80db342f-2325-481e-9780-a562054c816b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"pl_core_news_sm\")\n",
    "\n",
    "def get_entities(texts):\n",
    "    entities = []\n",
    "    \n",
    "    for text in texts:\n",
    "        doc = nlp(text)\n",
    "        entities += [(ent.lemma_, ent.label_) for ent in doc.ents]\n",
    "\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e2fe3ac9-1c5b-4f2e-93a6-d07f88b9b51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpaCy entity count:  51\n"
     ]
    }
   ],
   "source": [
    "spacy_entities = get_entities(text_list)\n",
    "print(\"SpaCy entity count: \", len(spacy_entities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "90e242eb-3bce-4bd2-96f4-45220f6e5fef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['geogName', 'persName', 'placeName', 'date', 'orgName']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list({item[1] for item in spacy_entities})\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae2f73bb-e539-4faf-882c-7d55bbc3e6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def run_ollama(model, text):\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"ollama\", \"run\", model, text],\n",
    "            text=True,\n",
    "            capture_output=True,\n",
    "            encoding=\"utf-8\",\n",
    "            check=True\n",
    "        )\n",
    "        raw_output = result.stdout\n",
    "        # print(f\"Raw output: {raw_output}\")\n",
    "    \n",
    "        return raw_output\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "202fdf61-60b0-4a21-95e2-91ab30acdb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_prompts(model_name, prompt, text_list):\n",
    "    results = []\n",
    "    for text in text_list:\n",
    "        result = run_ollama(model_name, prompt.format(text=text))\n",
    "        results.append(result)\n",
    "        print(len(results))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f9155e5a-1ebf-4b1b-ae86-2ab3349ac1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "zero_fiqa_results = run_prompts(model_name, zero_shot_prompt_pl, text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0c98e560-6d00-4742-a26d-c004fc0b1f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "few_fiqa_results = run_prompts(model_name, few_shot_prompt_pl, text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2136a5ed-d91f-4afa-ade6-d4667af76d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_tuples(text_list):\n",
    "    extracted_tuples = []\n",
    "    \n",
    "    tuple_pattern = r'\\(\\s*[\"\\'](.*?)[\"\\']\\s*,\\s*[\"\\'](.*?)[\"\\']\\s*\\)'\n",
    "    \n",
    "    for text in text_list:\n",
    "        matches = re.findall(tuple_pattern, text)\n",
    "        extracted_tuples.extend(matches)\n",
    "\n",
    "    non_empty_tuples = [t for t in extracted_tuples if t[0] != '']\n",
    "    \n",
    "    return non_empty_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "765081d8-3208-4fb2-be7a-db86aec206fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('HSA', 'orgName'),\n",
       " ('HSA', 'orgName'),\n",
       " ('HRA', 'orgName'),\n",
       " ('HSA', 'orgName'),\n",
       " ('HSA', 'orgName'),\n",
       " ('IRA', 'orgName'),\n",
       " ('Roth IRA', 'orgName'),\n",
       " ('HSA', 'orgName'),\n",
       " ('wypłata', 'persName'),\n",
       " ('HSA', 'orgName'),\n",
       " ('HSA', 'orgName'),\n",
       " ('HSA', 'orgName'),\n",
       " ('republikański', 'placeName'),\n",
       " ('Bóg', 'persName'),\n",
       " ('Amerykanów', 'placeName'),\n",
       " ('Trumpa', 'persName'),\n",
       " ('ACA', 'orgName'),\n",
       " ('Trump', 'persName'),\n",
       " ('Kongres', 'persName'),\n",
       " ('Trumpa', 'persName'),\n",
       " ('Ameryka', 'geogName'),\n",
       " ('GTFO', 'persName'),\n",
       " ('EOT', 'orgName'),\n",
       " ('MG Cranes w Ahmedabad', 'orgName'),\n",
       " ('Indie', 'placeName'),\n",
       " ('jakby być', 'persName'),\n",
       " ('DVR', 'orgName'),\n",
       " ('CableCard', 'persName'),\n",
       " ('TiVo', 'orgName'),\n",
       " ('OnDemand', 'persName'),\n",
       " ('gdybyś', 'persName'),\n",
       " ('TiVy', 'orgName'),\n",
       " ('Verse', 'persName'),\n",
       " ('AllVid', 'orgName'),\n",
       " ('TiVo', 'orgName'),\n",
       " ('TiVo', 'orgName'),\n",
       " ('Comcast', 'persName'),\n",
       " ('time Warner', 'persName'),\n",
       " ('comcast & TW', 'orgName'),\n",
       " ('HOA', 'orgName'),\n",
       " ('HOA', 'orgName'),\n",
       " ('HOA', 'orgName'),\n",
       " ('rok 2015', 'date'),\n",
       " ('RMD', 'orgName'),\n",
       " ('RMD', 'orgName'),\n",
       " ('RMD', 'orgName'),\n",
       " ('IRA', 'orgName'),\n",
       " ('Roth', 'orgName'),\n",
       " ('RMD', 'orgName'),\n",
       " ('IRA', 'orgName'),\n",
       " ('E-1031', 'persName')]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8f3f00b1-24da-431f-b124-04157cdf3667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('HSA', 'orgName'),\n",
       " ('8889', 'date'),\n",
       " ('Trump', 'persName'),\n",
       " ('ACA', 'orgName'),\n",
       " ('50', 'age'),\n",
       " ('college', 'placeName'),\n",
       " ('CD', 'time'),\n",
       " ('funduszu awaryjnego', 'orgName'),\n",
       " ('TiVo', 'orgName'),\n",
       " ('CableCard', 'orgName'),\n",
       " ('FIOS', 'orgName'),\n",
       " ('U-Verse', 'orgName'),\n",
       " ('AllVid', 'orgName'),\n",
       " ('Comcast', 'orgName'),\n",
       " ('Time Warner', 'orgName'),\n",
       " ('HOA', 'orgName'),\n",
       " ('stowarzyszenie mieszkań własnościowych', 'orgName'),\n",
       " ('stowarzyszenie condo', 'orgName'),\n",
       " ('2015', 'date'),\n",
       " ('18 000 USD', 'time'),\n",
       " ('5500 USD', 'time')]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_cleaned = extract_tuples(zero_fiqa_results)\n",
    "zero_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fbb9e9dd-6d83-496f-b91a-83da056129e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('HSA', 'orgName'),\n",
       " ('FSA', 'orgName'),\n",
       " ('HRA', 'orgName'),\n",
       " ('Pub. 969', 'date'),\n",
       " ('8889', 'date'),\n",
       " ('MG Cranes', 'orgName'),\n",
       " ('Ahmedabad', 'placeName'),\n",
       " ('Uniwersytet Jagielloński', 'orgName'),\n",
       " ('Kraków', 'placeName'),\n",
       " ('Grunwald', 'placeName'),\n",
       " ('15 lipca 1410', 'date'),\n",
       " ('Google', 'orgName'),\n",
       " ('Warszawa', 'placeName'),\n",
       " ('2021', 'date'),\n",
       " ('Warszawa', 'placeName'),\n",
       " ('Polska', 'geogName'),\n",
       " ('2023', 'date'),\n",
       " ('Jan Kowalski', 'persName'),\n",
       " ('XYZ', 'orgName'),\n",
       " ('Uniwersytet Jagielloński', 'orgName'),\n",
       " ('Kraków', 'placeName'),\n",
       " ('Grunwald', 'placeName'),\n",
       " ('15 lipca 1410', 'date'),\n",
       " ('Google', 'orgName'),\n",
       " ('Warszawa', 'placeName'),\n",
       " ('2021', 'date'),\n",
       " ('Warszawa', 'placeName'),\n",
       " ('Polska', 'geogName'),\n",
       " ('2023', 'date'),\n",
       " ('Jan Kowalski', 'persName'),\n",
       " ('XYZ', 'orgName'),\n",
       " ('TiVo', 'orgName'),\n",
       " ('CableCard', 'orgName'),\n",
       " ('FIOS', 'orgName'),\n",
       " ('U-Verse', 'orgName'),\n",
       " ('Comcast', 'orgName'),\n",
       " ('Time Warner', 'orgName'),\n",
       " ('Grunwald', 'placeName'),\n",
       " ('Kraków', 'placeName'),\n",
       " ('Warszawa', 'placeName'),\n",
       " ('Uniwersytet Jagielloński', 'orgName'),\n",
       " ('Kraków', 'placeName'),\n",
       " ('Grunwald', 'placeName'),\n",
       " ('15 lipca 1410', 'date'),\n",
       " ('Google', 'orgName'),\n",
       " ('Warszawa', 'placeName'),\n",
       " ('2021', 'date'),\n",
       " ('Uniwersytet Jagielloński', 'orgName'),\n",
       " ('Kraków', 'placeName'),\n",
       " ('Grunwald', 'placeName'),\n",
       " ('15 lipca 1410', 'date'),\n",
       " ('Google', 'orgName'),\n",
       " ('Warszawa', 'placeName'),\n",
       " ('2021', 'date'),\n",
       " ('2015', 'date'),\n",
       " ('34,2', 'time'),\n",
       " ('60', 'time'),\n",
       " ('53,3', 'time'),\n",
       " ('Evostfitness', 'orgName'),\n",
       " ('Fitness Strength', 'orgName'),\n",
       " ('Best Home Gym Equipment', 'orgName'),\n",
       " ('E-1031', 'time'),\n",
       " ('www.evostfitness.com', 'placeName'),\n",
       " ('support@evostfitness.com', 'placeName')]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "few_cleaned = extract_tuples(few_fiqa_results)\n",
    "few_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb6c6e26-7411-43bb-9637-f07d20e112e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"SpeakLeash/bielik-11b-v2.2-instruct:Q4_K_M\"\n",
    "\n",
    "zero_shot_prompt_pl = \"\"\"\n",
    "Wyodrębnij nazwane encje z poniższego tekstu i zaklasyfikuj je do \n",
    "jednej z następujących kategorii: ['geogName', 'date', 'placeName', 'persName', 'orgName', 'time']. \n",
    "Zwróć wynik jako listę w formacie: [(encja_1, kategotria_1), (encja_2, kategoria_2), ...].\n",
    "NIE POKAZUJ ŻADNEGO KODU. ZWRÓĆ TYLKO WYNIK. NIE PISZ WYJAŚNIEŃ.\n",
    "\n",
    "Tekst: {text}\"\n",
    "\"\"\"\n",
    "\n",
    "few_shot_prompt_pl = \"\"\"\n",
    "Wyodrębnij nazwane encje z poniższego tekstu i zaklasyfikuj je do \n",
    "jednej z następujących kategorii: ['geogName', 'date', 'placeName', 'persName', 'orgName', 'time']. \n",
    "Zwróć wynik jako listę w formacie: [(encja_1, kategotria_1), (encja_2, kategoria_2), ...].\n",
    "NIE POKAZUJ ŻADNEGO KODU. ZWRÓĆ TYLKO WYNIK.\n",
    "\n",
    "Tekst: {text}\"\n",
    "\n",
    "Przykład 1:\n",
    "Tekst: \"Uniwersytet Jagielloński znajduje się w Krakowie.\"\n",
    "Wynik: [(\"Uniwersytet Jagielloński\", \"orgName\"), (\"Kraków\", \"placeName\")]\n",
    "\n",
    "Przykład 2:\n",
    "Tekst: \"Bitwa pod Grunwaldem odbyła się 15 lipca 1410 roku.\"\n",
    "Wynik: [(\"Grunwald\", \"placeName\"), (\"15 lipca 1410\", \"date\")]\n",
    "\n",
    "Przykład 3:\n",
    "Tekst: \"Google otworzyło nowe biuro w Warszawie w 2021 roku.\"\n",
    "Wynik: [(\"Google\", \"orgName\"), (\"Warszawa\", \"placeName\"), (\"2021\", \"date\")]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cd9a9f0e-8a59-40f6-9c4a-d676e1281924",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_texts = [\n",
    "    \"Warszawa jest stolicą Polski i największym miastem w kraju.\",\n",
    "    \"W 2016 roku Polska przyjęła szczyt NATO, który odbył się w Warszawie.\",\n",
    "    \"Gdańsk, miasto portowe nad Bałtykiem, jest ważnym ośrodkiem historycznym i kulturalnym.\",\n",
    "    \"Nazwa Google pochodzi od terminu googol czyli liczby składającą się z 1 i 100 zer.\",\n",
    "    \"Aktualnym kanclerzem Niemiec jest Olaf Scholz, działacz SPD.\",\n",
    "    \"Maria Nowak wyjechała do Paryża na konferencję organizowaną przez UNESCO w maju 2023 roku.\",\n",
    "    \"Wczoraj odwiedziłem Park Narodowy Białowieski, gdzie spotkałem żubra o imieniu Wojtek.\",\n",
    "    \"Niedawno Tesla ogłosiła partnerstwo z firmą Panasonic w celu rozwoju baterii do samochodów elektrycznych.\",\n",
    "    \"Amazon planuje otworzyć nowy magazyn w Krakowie do końca przyszłego roku.\",\n",
    "    \"Ulubionymi postaciami mojego brata są Hyzio, Dyzio i Zyzio. Kaczor Donald miał się opiekować nimi tymczasowo, dopóki ich ojciec nie wróci ze szpitala, gdzie trafił po jednym z ich wybryków. Rodzice nie wezwali synów do domu, więc Kaczor Donald w 1947 zaadoptował swoich siostrzeńców.\"\n",
    "    \"Albert Einstein zmarł 18 kwietnia 1955 roku. Był fizykiem-teoretykiem, twórcą szczególnej teorii względności.\",\n",
    "    \"W 1865 roku James Clerk Maxwell wysunął przypuszczenie, że światło jest falą elektromagnetyczną. Hipoteza ta została potwierdzona eksperymentalnie w 1889 roku przez Heinricha Hertza, który odkrył fale radiowe.\",\n",
    "    \"Wybrzeże Kości Słoniowej to kolejne państwo Afryki Zachodniej, w którym byłe mocarstwo kolonialne zostało zmuszone do zakończenia obecności militarnej. Francja traci wpływy w regionie na rzecz Rosji.\",\n",
    "    \"Polski nauczyciel Włodzimierz Bubak został uhonorowany tytułem zdjęcia dnia NASA. Fotografia przedstawia wschód Oriona nad Babią Górą, a wykonana została w noc przesilenia zimowego.\",\n",
    "    \"W 2011 roku przywództwo w Korei Północnej przejął Kim Dzong Un.\",\n",
    "    \"Polski startup Brainly pozyskał finansowanie od inwestorów z Doliny Krzemowej.\",\n",
    "    \"Firma CD Projekt ogłosiła premierę nowej gry w grudniu 2024 roku.\",\n",
    "    \"Allegro wprowadziło nową usługę dostawy w ciągu 24 godzin na terenie Polski.\",\n",
    "    \"W Katowicach oraz Rudzie Śląskiej Porsche otworzyło nowy salon samochodowy.\",\n",
    "    \"Wczoraj poszedłem do sklepu i kupiłem sobie chleb i mleko.\"\n",
    "]\n",
    "\n",
    "ground_truth_one_list = [\n",
    "    (\"Warszawa\", \"placeName\"), (\"Polska\", \"placeName\"),\n",
    "    (\"2016\", \"date\"), (\"Polska\", \"placeName\"), (\"Warszawa\", \"placeName\"),\n",
    "    (\"Gdańsk\", \"placeName\"), (\"Bałtyk\", \"geogName\"),\n",
    "    (\"Google\", \"orgName\"),\n",
    "    (\"Olaf Scholz\", \"persName\"), (\"Niemcy\", \"placeName\"), (\"SPD\", \"orgName\"),\n",
    "    (\"Maria Nowak\", \"persName\"), (\"Paryż\", \"placeName\"), (\"UNESCO\", \"orgName\"), (\"2023\", \"date\"),\n",
    "    (\"Białowieski\", \"placeName\"), (\"Wojtek\", \"persName\"),\n",
    "    (\"Tesla\", \"orgName\"), (\"Panasonic\", \"orgName\"),\n",
    "    (\"Amazon\", \"orgName\"), (\"Kraków\", \"placeName\"), (\"2024\", \"date\"),\n",
    "    (\"Hyzio\", \"persName\"), (\"Dyzio\", \"persName\"), (\"Zyzio\", \"persName\"), (\"Kaczor Donald\", \"persName\"), (\"1947\", \"date\"),\n",
    "    (\"Albert Einstein\", \"persName\"), (\"1955\", \"date\"),\n",
    "    (\"1865\", \"date\"), (\"James Clerk Maxwell\", \"persName\"), (\"Heinrich Hertz\", \"persName\"),\n",
    "    (\"Wybrzeże Kości Słoniowej\", \"placeName\"), (\"Francja\", \"placeName\"), (\"Rosja\", \"placeName\"),\n",
    "    (\"Włodzimierz Bubak\", \"persName\"), (\"NASA\", \"orgName\"), (\"Orion\", \"geogName\"), (\"Babia Góra\", \"geogName\"),\n",
    "    (\"2011\", \"date\"), (\"Kim Dzong Un\", \"persName\"), (\"Korea Północna\", \"placeName\"),\n",
    "    (\"Brainly\", \"orgName\"), (\"Dolina Krzemowa\", \"geogName\"),\n",
    "    (\"CD Projekt\", \"orgName\"), (\"2024\", \"date\"),\n",
    "    (\"Allegro\", \"orgName\"), (\"24 godzin\", \"time\"), (\"Polska\", \"placeName\"),\n",
    "    (\"Katowice\", \"placeName\"), (\"Ruda Śląska\", \"placeName\"), (\"Porsche\", \"orgName\"),\n",
    "    (\"wczoraj\", \"time\")\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6c7b08fc-34b9-4b77-aa6a-4a6df0de2d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(ground_truth, predictions):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "\n",
    "    # eliminujemy case-sensitiveness\n",
    "    predicted_entities = set((ent[0].lower(), ent[1]) for ent in predictions)\n",
    "    true_entities = set((ent[0].lower(), ent[1]) for ent in ground_truth)\n",
    "\n",
    "    tp = len(predicted_entities & true_entities) \n",
    "    fp = len(predicted_entities - true_entities)\n",
    "    fn = len(true_entities - predicted_entities)\n",
    "\n",
    "    print(\"TP: \", tp)\n",
    "    print(\"FP: \", fp)\n",
    "    print(\"FN: \", fn)\n",
    "\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "\n",
    "    result_dict = {\"precision\": precision, \"recall\": recall, \"F1-score\": f1}\n",
    "    \n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "450e21a9-c9aa-4ad6-8f62-4575a97a4b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpaCy entity count:  51\n"
     ]
    }
   ],
   "source": [
    "spacy_custom = get_entities(custom_texts)\n",
    "print(\"SpaCy entity count: \", len(spacy_custom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "089c349d-9fdc-411b-b89a-47c2f082e5d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('warszawa', 'placeName'),\n",
       " ('Polska', 'placeName'),\n",
       " ('2016 rok', 'date'),\n",
       " ('Polska', 'placeName'),\n",
       " ('NATO', 'orgName'),\n",
       " ('Warszawa', 'placeName'),\n",
       " ('Gdańsk', 'placeName'),\n",
       " ('Bałtyk', 'geogName'),\n",
       " ('Google', 'orgName'),\n",
       " ('Niemcy', 'placeName'),\n",
       " ('olaf Scholz', 'persName'),\n",
       " ('SPD', 'orgName'),\n",
       " ('Maria Nowak', 'persName'),\n",
       " ('Paryż', 'placeName'),\n",
       " ('UNESCO', 'orgName'),\n",
       " ('maj 2023 rok', 'date'),\n",
       " ('park narodowy', 'geogName'),\n",
       " ('Wojtek', 'persName'),\n",
       " ('amazon', 'persName'),\n",
       " ('Kraków', 'placeName'),\n",
       " ('Hyzio', 'persName'),\n",
       " ('Dyzio', 'persName'),\n",
       " ('Zyzio', 'persName'),\n",
       " ('Donald', 'persName'),\n",
       " ('Kaczor Donald', 'persName'),\n",
       " ('1947', 'date'),\n",
       " ('Albert Einstein', 'persName'),\n",
       " ('18 kwiecień 1955 rok', 'date'),\n",
       " ('1865 rok', 'date'),\n",
       " ('James clerk Maxwell', 'persName'),\n",
       " ('1889 rok', 'date'),\n",
       " ('Heinrich Hertza', 'persName'),\n",
       " ('Afryka Zachodniej', 'geogName'),\n",
       " ('Francja', 'placeName'),\n",
       " ('Rosja', 'placeName'),\n",
       " ('polski', 'placeName'),\n",
       " ('Włodzimierz Bubak', 'persName'),\n",
       " ('NASA', 'orgName'),\n",
       " ('Orion', 'geogName'),\n",
       " ('Babia Góra', 'geogName'),\n",
       " ('2011 rok', 'date'),\n",
       " ('Korea północny', 'placeName'),\n",
       " ('kto Dzong Un.', 'persName'),\n",
       " ('polski', 'placeName'),\n",
       " ('Brainly', 'persName'),\n",
       " ('dolina krzemowy', 'geogName'),\n",
       " ('CD projekt', 'orgName'),\n",
       " ('grudzień 2024 rok', 'date'),\n",
       " ('Polska', 'placeName'),\n",
       " ('Katowice', 'placeName'),\n",
       " ('Rudzie Śląskiej Porsche', 'placeName')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "57fc2d50-b16d-4563-900e-a1f9165d457b",
   "metadata": {},
   "outputs": [],
   "source": [
    "part1 = custom_texts[:10]\n",
    "part2 = custom_texts[10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7049c575-43a5-4f35-81a2-bfd043b76545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "part1_results = run_prompts(model_name, zero_shot_prompt_pl, part1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce94bcca-5da9-4d1d-85cb-5a7f8c020c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "part2_results = run_prompts(model_name, zero_shot_prompt_pl, part2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "af06d70e-870d-408e-8839-512d995c76ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bielik entity count:  57\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Warszawa', 'placeName'),\n",
       " ('Polska', 'geogName'),\n",
       " ('Polska', 'orgName'),\n",
       " ('2016', 'date'),\n",
       " ('Warszawa', 'placeName'),\n",
       " ('Gdańsk', 'placeName'),\n",
       " ('Bałtyk', 'geogName'),\n",
       " ('Google', 'orgName'),\n",
       " ('googol', 'persName'),\n",
       " ('Niemiec', 'geogName'),\n",
       " ('Olaf Scholz', 'persName'),\n",
       " ('SPD', 'orgName'),\n",
       " ('Maria Nowak', 'persName'),\n",
       " ('Paryża', 'placeName'),\n",
       " ('UNESCO', 'orgName'),\n",
       " ('maju 2023 roku', 'date'),\n",
       " ('Wczoraj', 'date'),\n",
       " ('Park Narodowy Białowieski', 'placeName'),\n",
       " ('żubra', 'persName'),\n",
       " ('Wojtek', 'persName'),\n",
       " ('Tesla', 'orgName'),\n",
       " ('Panasonic', 'orgName'),\n",
       " ('Amazon', 'orgName'),\n",
       " ('Kraków', 'geogName'),\n",
       " ('Hyzio', 'persName'),\n",
       " ('Dyzio', 'persName'),\n",
       " ('Zyzio', 'persName'),\n",
       " ('Kaczor Donald', 'persName'),\n",
       " ('1947', 'date'),\n",
       " ('Albert Einstein', 'persName'),\n",
       " ('18 kwietnia 1955', 'date'),\n",
       " ('geogName', \"placeName', 'orgName', 'time\"),\n",
       " ('1865', 'date'),\n",
       " ('1889', 'date'),\n",
       " ('James Clerk Maxwell', 'persName'),\n",
       " ('Heinrich Hertz', 'persName'),\n",
       " ('Wybrzeże Kości Słoniowej', 'geogName'),\n",
       " ('Afryka Zachodnia', 'geogName'),\n",
       " ('Francja', 'orgName'),\n",
       " ('Rosja', 'orgName'),\n",
       " ('Włodzimierz Bubak', 'persName'),\n",
       " ('NASA', 'orgName'),\n",
       " ('Orion', 'geogName'),\n",
       " ('Babia Góra', 'placeName'),\n",
       " ('2011', 'date'),\n",
       " ('Korea Północna', 'geogName'),\n",
       " ('Kim Dzong Un', 'persName'),\n",
       " ('Brainly', 'orgName'),\n",
       " ('Dolina Krzemowa', 'placeName'),\n",
       " ('CD Projekt', 'orgName'),\n",
       " ('december', 'date'),\n",
       " ('Allegro', 'orgName'),\n",
       " ('Polska', 'geogName'),\n",
       " ('Katowice', 'placeName'),\n",
       " ('Ruda Śląska', 'placeName'),\n",
       " ('Wczoraj', 'date'),\n",
       " ('sklep', 'placeName')]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_results = part1_results + part2_results\n",
    "cleaned = extract_tuples(combined_results)\n",
    "print(\"Bielik entity count: \", len(cleaned))\n",
    "cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "96fa51fc-9464-4047-abe7-15cd006b8815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP:  28\n",
      "FP:  19\n",
      "FN:  21\n",
      "TP:  32\n",
      "FP:  22\n",
      "FN:  17\n"
     ]
    }
   ],
   "source": [
    "spacy_metrics = get_metrics(ground_truth_one_list, spacy_custom)\n",
    "llm_metrics = get_metrics(ground_truth_one_list, cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4cc682-b5dc-48c0-b842-63bc9a929709",
   "metadata": {},
   "source": [
    "| Model | True Positives (TP) | False Positives (FP) | False Negatives (FN) |\n",
    "|-------|---------------------|----------------------|----------------------|\n",
    "| SpaCy | 28                  | 19                   | 21                   |\n",
    "| LLM   | 32                  | 22                   | 17                   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcde9dc-cd67-4271-b6d6-890b0428aa1c",
   "metadata": {},
   "source": [
    "### Analyze error patterns and classification mistakes\n",
    "\n",
    "Analyzing the results presented in the table, we can observe that the errors made by the compared approaches (SpaCy and LLM) are quite similar. In the case of SpaCy, errors were more often related to missing entities that should have been identified. On the other hand, the LLM tended to classify words as entities even when they were not. However, the differences in these metrics are so small that they might be attributed to the specific dataset used rather than reflecting a general trend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "4ddaf0cf-6449-4f82-b3cb-42b2b8b05d3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpaCy:  {'precision': 0.5957446808510638, 'recall': 0.5714285714285714, 'F1-score': 0.5833333333333334}\n",
      "Bielik:  {'precision': 0.5925925925925926, 'recall': 0.6530612244897959, 'F1-score': 0.6213592233009709}\n"
     ]
    }
   ],
   "source": [
    "print(\"SpaCy: \", spacy_metrics)\n",
    "print(\"Bielik: \", llm_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04037bc1-c612-414e-80eb-b578a0409d5b",
   "metadata": {},
   "source": [
    "## Questions (2 points):\n",
    "\n",
    "### 1. How does the performance of LLM-based NER compare to traditional approaches? What are the trade-offs in terms of accuracy, speed, and resource usage?\n",
    "\n",
    "#### FiQa-pl dataset\n",
    "The experiment was conducted on 10 texts due to the long response time of the Bielik model (11 billion parameters). On this dataset, SpaCy performed the best. Although it made some errors, it identified the most actual entities. Bielik also performed decently but introduced additional categories, such as \"age,\" even though they were not included in the provided list of allowed categories.\n",
    "\n",
    "#### Custom dataset\n",
    "\n",
    "For the 20 custom questions, Bielik outperformed SpaCy in terms of metrics, primarily due to its better lemmatization capabilities. Some examples: \n",
    "\n",
    "| Original Form        | SpaCy                | Bielik            |\n",
    "|----------------------|----------------------|-------------------|\n",
    "| Heinricha Hertza     | Heinrich Hertza      | Heinrich Hertz    |\n",
    "| Kim Dzong Un         | kto Dzong Un         | Kim Dzong Un      |\n",
    "| Doliny Krzemowej     | dolina krzemowy      | Dolina Krzemowa   |\n",
    "\n",
    "\n",
    "Nevertheless, SpaCy could have performed better than Bielik if not for issues related to lemmatization. I decided not to be case-sensitive when comparing the results\n",
    "\n",
    "Bielik performs the task quite well, but it has significant limitations. It's necessary to make the right prompts to ensure the model returns only what is needed, without explaining why or providing the code behind the process. Additionally, the response time is much longer for this model. While it is quite large, leading to better results, the trade-off is a longer wait time for answers. It also consumes significantly more resource consuming.\n",
    "\n",
    "### 2. Which prompting strategy proved most effective for NER and classification tasks? Why?\n",
    "\n",
    "Zero-shot prompting performed better. The model works slightly faster in that case, and I've noticed it has a better ability to generalize. Few-shot prompts provide some context, which the model sometimes tries to adhere to too much.\n",
    "\n",
    "### 3. What are the limitations and potential biases of using LLMs for NER and classification?\n",
    "\n",
    "The main limitations are the response time, resource consumption, and inconsistency of the answers. The model occasionally returns responses that do not have the structure we expect. As a result, we need to write a function that can extract the desired information. However, it's not easy to create a function that will correctly extract the right answer in every case, which means we may occasionally miss some results.\n",
    "\n",
    "### 4. In what scenarios would you recommend using traditional NER vs. LLM-based approaches?\n",
    "\n",
    "If the task is not being performed on a large scale and we have some time, I would recommend using an LLM. In case of any errors or doubts, the model can explain why it made a certain decision and can potentially improve based on our feedback.\n",
    "\n",
    "In other situations, although SpaCy is not perfect, it is good enough in many cases. It is much faster and returns results immediately in the expected format, making the workflow much easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710acbb0-c8a6-472c-9d5a-5fdbd8e34819",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
